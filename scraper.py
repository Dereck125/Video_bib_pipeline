import asyncio
import json
import re
from pathlib import Path
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError
from datetime import datetime

# Estructura de la Biblia
BIBLE_STRUCTURE = {
    "genesis": 50, "exodo": 40, "levitico": 27, "numeros": 36, "deuteronomio": 34,
    "josue": 24, "jueces": 21, "rut": 4, "1-samuel": 31, "2-samuel": 24,
    "1-reyes": 22, "2-reyes": 25, "1-cronicas": 29, "2-cronicas": 36,
    "esdras": 10, "nehemias": 13, "ester": 10, "job": 42, "salmos": 150,
    "proverbios": 31, "eclesiastes": 12, "cantares": 8, "isaias": 66,
    "jeremias": 52, "lamentaciones": 5, "ezequiel": 48, "daniel": 12,
    "oseas": 14, "joel": 3, "amos": 9, "abdias": 1, "jonas": 4, "miqueas": 7,
    "nahum": 3, "habacuc": 3, "sofonias": 3, "hageo": 2, "zacarias": 14,
    "malaquias": 4, "mateo": 28, "marcos": 16, "lucas": 24, "juan": 21,
    "hechos": 28, "romanos": 16, "1-corintios": 16, "2-corintios": 13,
    "galatas": 6, "efesios": 6, "filipenses": 4, "colosenses": 4,
    "1-tesalonicenses": 5, "2-tesalonicenses": 3, "1-timoteo": 6,
    "2-timoteo": 4, "tito": 3, "filemon": 1, "hebreos": 13, "santiago": 5,
    "1-pedro": 5, "2-pedro": 3, "1-juan": 5, "2-juan": 1, "3-juan": 1,
    "judas": 1, "apocalipsis": 22
}

class BibleScraper:
    def __init__(self, headless=True, delay=0.5):
        self.headless = headless
        self.delay = delay
        self.base_url = "https://www.biblia.es/biblia-buscar-libros-1.php"
        self.version = "rv60"
        self.bible_data = {}
        self.stats = {"success": 0, "errors": 0, "total": 0}
        
    def parse_verses(self, text):
        """Extrae vers√≠culos del texto usando regex"""
        verses = {}
        
        # Limpiar el texto
        text = text.strip()
        
        # Patr√≥n para detectar vers√≠culos: n√∫mero seguido de texto
        # Formato: "1Texto del vers√≠culo" o "1 Texto del vers√≠culo"
        pattern = r'(\d+)\s*([^0-9]+?)(?=\d+\s*[A-Z√Å√â√ç√ì√ö√ë]|$)'
        
        matches = re.finditer(pattern, text, re.DOTALL)
        
        for match in matches:
            verse_num = match.group(1)
            verse_text = match.group(2).strip()
            
            # Limpiar texto del vers√≠culo
            verse_text = re.sub(r'\s+', ' ', verse_text)
            verse_text = verse_text.strip()
            
            if verse_text:
                verses[verse_num] = verse_text
        
        return verses
        
    async def scrape_chapter(self, page, book, chapter):
        """Extrae un cap√≠tulo espec√≠fico"""
        url = f"{self.base_url}?libro={book}&capitulo={chapter}&version={self.version}"
        
        try:
            self.stats["total"] += 1
            
            # Navegar a la p√°gina
            response = await page.goto(url, wait_until="domcontentloaded", timeout=30000)
            
            if response.status != 200:
                print(f"  ‚úó Error HTTP {response.status}: {book} {chapter}")
                self.stats["errors"] += 1
                return {}
            
            # Esperar a que cargue el contenido
            await page.wait_for_load_state("networkidle", timeout=10000)
            
            # M√©todo 1: Buscar en el main content
            verses = {}
            main_content = await page.query_selector('main')
            
            if main_content:
                text = await main_content.inner_text()
                verses = self.parse_verses(text)
            
            # M√©todo 2: Si no encuentra nada, buscar en todo el body
            if not verses:
                body = await page.query_selector('body')
                if body:
                    text = await body.inner_text()
                    # Extraer solo la secci√≥n relevante (despu√©s de "Cap√≠tulo X")
                    chapter_pattern = f"Cap√≠tulo {chapter}"
                    if chapter_pattern in text:
                        text = text.split(chapter_pattern, 1)[1]
                        # Tomar hasta el siguiente "Cap√≠tulo" o hasta el final
                        next_chapter = text.find("Cap√≠tulo")
                        if next_chapter > 0:
                            text = text[:next_chapter]
                    
                    verses = self.parse_verses(text)
            
            if verses:
                print(f"  ‚úì {book.title():20} Cap {chapter:3}: {len(verses):3} vers√≠culos")
                self.stats["success"] += 1
            else:
                print(f"  ‚ö† {book.title():20} Cap {chapter:3}: No se encontraron vers√≠culos")
                self.stats["errors"] += 1
            
            return verses
            
        except PlaywrightTimeoutError:
            print(f"  ‚úó Timeout: {book} {chapter}")
            self.stats["errors"] += 1
            return {}
        except Exception as e:
            print(f"  ‚úó Error en {book} {chapter}: {str(e)[:50]}")
            self.stats["errors"] += 1
            return {}
    
    async def scrape_book(self, page, book, num_chapters):
        """Extrae todos los cap√≠tulos de un libro"""
        print(f"\n{'='*60}")
        print(f"üìñ {book.upper()} ({num_chapters} cap√≠tulos)")
        print('='*60)
        
        book_data = {}
        for chapter in range(1, num_chapters + 1):
            verses = await self.scrape_chapter(page, book, chapter)
            book_data[str(chapter)] = verses
            
            # Delay para no sobrecargar el servidor
            await asyncio.sleep(self.delay)
        
        return book_data
    
    async def scrape_all(self, start_from=None, limit=None, books_list=None):
        """Extrae toda la Biblia o libros espec√≠ficos"""
        async with async_playwright() as p:
            print("üöÄ Iniciando scraper de la Biblia Reina Valera 1960")
            print("="*60)
            
            browser = await p.chromium.launch(headless=self.headless)
            context = await browser.new_context(
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            )
            page = await context.new_page()
            
            # Determinar qu√© libros extraer
            if books_list:
                books = [(book, BIBLE_STRUCTURE[book]) for book in books_list if book in BIBLE_STRUCTURE]
            else:
                books = list(BIBLE_STRUCTURE.items())
            
            # Comenzar desde un libro espec√≠fico
            if start_from:
                start_idx = next((i for i, (book, _) in enumerate(books) if book == start_from), 0)
                books = books[start_idx:]
            
            # Limitar cantidad de libros
            if limit:
                books = books[:limit]
            
            total_books = len(books)
            start_time = datetime.now()
            
            for idx, (book, num_chapters) in enumerate(books, 1):
                print(f"\nüìö Progreso: {idx}/{total_books} libros")
                self.bible_data[book] = await self.scrape_book(page, book, num_chapters)
                
                # Guardar progreso cada 5 libros
                if idx % 5 == 0:
                    self.save_progress(f"biblia_progreso_{idx}_libros.json")
            
            await browser.close()
            
            # Estad√≠sticas finales
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            print("\n" + "="*60)
            print("‚úÖ SCRAPING COMPLETADO")
            print("="*60)
            print(f"‚è±Ô∏è  Tiempo total: {duration:.2f} segundos")
            print(f"üìä Cap√≠tulos exitosos: {self.stats['success']}")
            print(f"‚ùå Cap√≠tulos con error: {self.stats['errors']}")
            print(f"üìà Total intentado: {self.stats['total']}")
            print(f"‚ú® Tasa de √©xito: {(self.stats['success']/self.stats['total']*100):.1f}%")
    
    def save_progress(self, filename="biblia_reina_valera_1960.json"):
        """Guarda el progreso en JSON"""
        output_dir = Path("output")
        output_dir.mkdir(exist_ok=True)
        
        filepath = output_dir / filename
        
        # Calcular estad√≠sticas
        total_chapters = sum(len(chapters) for chapters in self.bible_data.values())
        total_verses = sum(
            len(verses) 
            for book in self.bible_data.values() 
            for verses in book.values()
        )
        
        data = {
            "metadata": {
                "version": "Reina Valera 1960",
                "fecha_extraccion": datetime.now().isoformat(),
                "total_libros": len(self.bible_data),
                "total_capitulos": total_chapters,
                "total_versiculos": total_verses,
                "fuente": "https://www.biblia.es"
            },
            "libros": self.bible_data
        }
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        size_kb = filepath.stat().st_size / 1024
        print(f"\nüíæ Guardado: {filepath}")
        print(f"   üìö Libros: {len(self.bible_data)}")
        print(f"   üìñ Cap√≠tulos: {total_chapters}")
        print(f"   üìù Vers√≠culos: {total_verses}")
        print(f"   üíø Tama√±o: {size_kb:.2f} KB")
    
    def save_by_book(self):
        """Guarda cada libro en un archivo JSON separado"""
        output_dir = Path("output/por_libro")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        for book, chapters in self.bible_data.items():
            filepath = output_dir / f"{book}.json"
            
            total_verses = sum(len(verses) for verses in chapters.values())
            
            data = {
                "metadata": {
                    "libro": book,
                    "version": "Reina Valera 1960",
                    "total_capitulos": len(chapters),
                    "total_versiculos": total_verses,
                    "fecha_extraccion": datetime.now().isoformat()
                },
                "capitulos": chapters
            }
            
            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"\n‚úÖ {len(self.bible_data)} libros guardados en {output_dir}")


async def main():
    """Funci√≥n principal con diferentes modos de uso"""
    
    # MODO 1: PRUEBA R√ÅPIDA (solo 1 libro)
    #print("üß™ MODO PRUEBA: Extrayendo solo G√©nesis...")
    #scraper = BibleScraper(headless=False, delay=0.3)
    #await scraper.scrape_all(books_list=["genesis"])
    #scraper.save_progress("test_genesis.json")
    
    # MODO 2: PRUEBA MEDIANA (primeros 3 libros)
    # scraper = BibleScraper(headless=True, delay=0.5)
    # await scraper.scrape_all(limit=3)
    # scraper.save_progress("test_3_libros.json")
    
    # MODO 3: EXTRAER TODO EL ANTIGUO TESTAMENTO
    # antiguo_testamento = [
    #     "genesis", "exodo", "levitico", "numeros", "deuteronomio",
    #     "josue", "jueces", "rut", "1-samuel", "2-samuel",
    #     "1-reyes", "2-reyes", "1-cronicas", "2-cronicas",
    #     "esdras", "nehemias", "ester", "job", "salmos",
    #     "proverbios", "eclesiastes", "cantares", "isaias",
    #     "jeremias", "lamentaciones", "ezequiel", "daniel",
    #     "oseas", "joel", "amos", "abdias", "jonas", "miqueas",
    #     "nahum", "habacuc", "sofonias", "hageo", "zacarias", "malaquias"
    # ]
    # scraper = BibleScraper(headless=True, delay=0.5)
    # await scraper.scrape_all(books_list=antiguo_testamento)
    # scraper.save_progress("antiguo_testamento.json")
    # scraper.save_by_book()
    
    # MODO 4: EXTRAER TODA LA BIBLIA
    #scraper = BibleScraper(headless=True, delay=0.5)
    #await scraper.scrape_all()
    #scraper.save_progress("biblia_completa_rv1960.json")
    #scraper.save_by_book()
    
    # MODO 5: CONTINUAR DESDE UN LIBRO ESPEC√çFICO
    # scraper = BibleScraper(headless=True, delay=0.5)
    # await scraper.scrape_all(start_from="mateo")
    # scraper.save_progress("nuevo_testamento.json")
    
    print("\nüéâ ¬°Proceso completado!")


if __name__ == "__main__":
    asyncio.run(main())